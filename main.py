from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import google.generativeai as genai
import os
import json
import requests
from io import StringIO

app = FastAPI()

# CORS ì„¤ì •: í”„ë¡ íŠ¸ì—”ë“œ ì ‘ì† í—ˆìš©
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# ---------------------------------------------------------
# [ì„¤ì •] Renderì˜ Environment Variablesì—ì„œ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
# ---------------------------------------------------------
GITHUB_USER = os.getenv("GITHUB_USER", "your-github-id")
REPO_NAME = os.getenv("REPO_NAME", "your-repo-name")
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# Gemini AI ëª¨ë¸ ì„¤ì •
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel("gemini-2.0-flash")

BASE_URL = f"https://raw.githubusercontent.com/{GITHUB_USER}/{REPO_NAME}/main"

# ---------------------------------------------------------
# [ìœ í‹¸ë¦¬í‹°] ë³´ì•ˆ ê°•í™”ëœ ë°ì´í„° í˜¸ì¶œ í•¨ìˆ˜ (Token ì‚¬ìš©)
# ---------------------------------------------------------
def fetch_csv(filename):
    try:
        url = f"{BASE_URL}/{filename}"
        headers = {"Authorization": f"token {GITHUB_TOKEN}"} if GITHUB_TOKEN else {}
        res = requests.get(url, headers=headers)
        
        if res.status_code == 200:
            df = pd.read_csv(StringIO(res.text), encoding='utf-8-sig')
            df.columns = df.columns.str.strip() # ì»¬ëŸ¼ëª… ê³µë°± ì œê±°
            return df.fillna("")
        else:
            print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {filename} (Status: {res.status_code})")
            return pd.DataFrame()
    except Exception as e:
        print(f"ğŸš¨ ë°ì´í„° í˜¸ì¶œ ì—ëŸ¬: {e}")
        return pd.DataFrame()

# ---------------------------------------------------------
# [API] ì´ˆê¸°í™” ë°ì´í„° (ë¦¬ë”ë³´ë“œ ë° í¬íŠ¸í´ë¦¬ì˜¤)
# ---------------------------------------------------------
@app.get("/api/init")
async def init():
    df_a = fetch_csv("CSV_A_Analysis.csv")
    df_c = fetch_csv("CSV_C.csv")
    df_e = fetch_csv("CSV_E.csv")
    
    # í¬íŠ¸í´ë¦¬ì˜¤ íŒŒì¼ ë¡œë“œ
    try:
        url = f"{BASE_URL}/portfolio.json"
        headers = {"Authorization": f"token {GITHUB_TOKEN}"} if GITHUB_TOKEN else {}
        res = requests.get(url, headers=headers)
        portfolio = res.json() if res.status_code == 200 else {"holdings": []}
    except:
        portfolio = {"holdings": []}

    return {
        "static": {
            "A": df_a.to_dict(orient='records'),
            "C": df_c.tail(5).to_dict(orient='records'),
            "E": df_e.tail(5).to_dict(orient='records')
        },
        "portfolio": portfolio
    }

# ---------------------------------------------------------
# [API] í†µí•© ë°ì´í„°íŒ© ê¸°ë°˜ ë”¥ëŸ¬ë‹ ë¶„ì„
# ---------------------------------------------------------
@app.post("/api/deep-analyze")
async def deep_analyze(req: Request):
    try:
        raw_info = await req.json()
        mode = raw_info.get("type", "SINGLE")
        
        # 1. í‹°ì»¤ ì¶”ì¶œ ë° 6ìë¦¬ í‘œì¤€í™”
        if mode == "PORTFOLIO":
            holdings = raw_info.get("portfolio", [])
            target_tickers = [str(h.get("code") or h.get("ticker")).strip().zfill(6) for h in holdings]
        else:
            code = str(raw_info.get("code") or raw_info.get("ticker") or "").strip().zfill(6)
            target_tickers = [code] if code != "000000" else []

        if not target_tickers:
            return {"analysis": "âŒ ë¶„ì„í•  ì¢…ëª© ì½”ë“œë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        # 2. í†µí•© ë°ì´í„°íŒ©(Final_Insight.csv) ë¡œë“œ
        df_insight = fetch_csv("Final_Insight.csv")
        if df_insight.empty:
            return {"analysis": "âŒ í†µí•© ë°ì´í„°íŒ©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. collector2.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•´ ì£¼ì„¸ìš”."}

        # 3. ë°ì´í„° ë§¤ì¹­ (Golden Key: ticker)
        matched_rows = df_insight[df_insight['ticker'].astype(str).str.zfill(6).isin(target_tickers)]
        
        if matched_rows.empty:
            return {"analysis": f"âŒ ì„ íƒí•˜ì‹  ì¢…ëª©({', '.join(target_tickers)})ì˜ í†µí•© ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}

        # 4. Gemini ì „ì†¡ìš© ë°ì´í„° êµ¬ì„±
        analysis_data = matched_rows.to_dict(orient='records')

        prompt = f"""
        ë‹¹ì‹ ì€ ì •í˜¸ë‹˜ì˜ ìˆ˜ì„ í€€íŠ¸ ì—ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. 2026ë…„ í˜„ì¬ ì‹œì¥ ìƒí™©ì„ ë°˜ì˜í•˜ì—¬ ë¶„ì„í•˜ì„¸ìš”.
        ë‹¤ìŒ ë°ì´í„°íŒ©ì—ëŠ” ê° ì¢…ëª©ì˜ ì ìˆ˜(A), ì‹œì¥ ìƒí™©(C), ì‹¬ë¦¬ ì§€í‘œ(E)ê°€ ëª¨ë‘ ê²°í•©ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

        [ë¶„ì„ ë°ì´í„°]
        {json.dumps(analysis_data, ensure_ascii=False)}

        [ìš”êµ¬ì‚¬í•­]
        1. ì¢…ëª©ì˜ ë“±ê¸‰ê³¼ Alpha ìˆ˜ì¹˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜„ì¬ íˆ¬ì ë§¤ë ¥ë„ë¥¼ ì§„ë‹¨í•˜ì„¸ìš”.
        2. 'macro_json'ê³¼ 'sentiment_json'ì„ ë¶„ì„í•˜ì—¬ ê±°ì‹œ ê²½ì œ í™˜ê²½ì´ ì¢…ëª©ì— ì£¼ëŠ” ì˜í–¥ì„ ì„¤ëª…í•˜ì„¸ìš”.
        3. 'ë°ì´í„° ì—†ìŒ'ì´ë¼ëŠ” í‘œí˜„ ëŒ€ì‹ , ì œê³µëœ ìˆ˜ì¹˜ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ êµ¬ì²´ì ì¸ ë§¤ìˆ˜/ë§¤ë„/ê´€ë§ ì „ëµì„ ì œì‹œí•˜ì„¸ìš”.
        4. ê²°ë¡  ë¶€ë¶„ì— 'ì¶”ì²œ ì¢…ëª©(6ìë¦¬ì½”ë“œ)' 3ê°œë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.
        """

        response = model.generate_content(prompt)
        return {"analysis": response.text}

    except Exception as e:
        return {"analysis": f"ğŸš¨ ë¶„ì„ ì¤‘ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {str(e)}"}

@app.post("/api/portfolio/save")
async def save_portfolio(req: Request):
    return {"status": "success"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
