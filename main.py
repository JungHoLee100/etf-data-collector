import pandas as pd
import os, json, requests, datetime, base64
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from google import genai
import pdfplumber
from pykrx import stock
import yfinance as yf
from io import BytesIO

app = FastAPI()
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
GITHUB_USER = "JungHoLee100"
REPO_NAME = "etf-data-collector"
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

# GitHub íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜
def github_file(path, content=None, method="GET"):
    url = f"https://api.github.com/repos/{GITHUB_USER}/{REPO_NAME}/contents/{path}"
    headers = {"Authorization": f"token {GITHUB_TOKEN}", "Accept": "application/vnd.github.v3+json"}
    if method == "GET":
        res = requests.get(url, headers=headers)
        if res.status_code == 200:
            info = res.json()
            return json.loads(base64.b64decode(info['content']).decode('utf-8-sig')), info['sha']
        return None, None
    else:
        _, sha = github_file(path)
        payload = {"message": "Update Portfolio", "content": base64.b64encode(content.encode('utf-8')).decode('utf-8')}
        if sha: payload["sha"] = sha
        return requests.put(url, headers=headers, json=payload)

@app.get("/api/init")
async def init():
    base_url = f"https://raw.githubusercontent.com/{GITHUB_USER}/{REPO_NAME}/main"
    data = {}
    for k, v in {"A": "CSV_A_Analysis.csv", "C": "CSV_C.csv", "E": "CSV_E.csv"}.items():
        try: data[k] = pd.read_csv(f"{base_url}/{v}", encoding='utf-8-sig').fillna(0).to_dict(orient="records")
        except: data[k] = []
    port, _ = github_file("portfolio.json")
    return {"static": data, "portfolio": port or {"holdings": []}}

@app.post("/api/portfolio/save")
async def save_port(req: Request):
    data = await req.json()
    github_file("portfolio.json", content=json.dumps(data, ensure_ascii=False), method="PUT")
    return {"status": "success"}

@app.post("/api/deep-analyze")
async def deep_analyze(req: Request):
    try:
        raw_info = await req.json()
        
        # [1] ë¶„ì„ ëª¨ë“œ íŒë³„ (ê°œë³„ ì¢…ëª© vs í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´)
        is_portfolio = raw_info.get("type") == "PORTFOLIO"
        holdings = raw_info.get("portfolio", [])

        # ë¶„ì„í•  í‹°ì»¤ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        if is_portfolio:
            target_tickers = [str(h.get("code") or "").strip() for h in holdings if h.get("code")]
            target_name = "ë‚´ í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´"
        else:
            code = str(raw_info.get("code") or "").replace("'", "").strip()
            target_tickers = [code] if code else []
            target_name = str(raw_info.get("name") or "ë¶„ì„ ëŒ€ìƒ")

        if not target_tickers:
            return {"analysis": "ë¶„ì„í•  ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. í¬íŠ¸í´ë¦¬ì˜¤ì— ì¢…ëª©ì„ ì¶”ê°€í•˜ê±°ë‚˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."}

        # [2] CSV ë°ì´í„° ë¡œë“œ (í‘œì¤€ ì‰¼í‘œ í˜•ì‹ ê¸°ë°˜)
        base_url = f"https://raw.githubusercontent.com/{GITHUB_USER}/{REPO_NAME}/main"
        def get_clean_df(filename):
            try:
                df = pd.read_csv(f"{base_url}/{filename}", encoding='utf-8-sig')
                df.columns = df.columns.str.strip()
                return df
            except: return pd.DataFrame()

        df_a = get_clean_df("CSV_A_Analysis.csv")
        df_c = get_clean_df("CSV_C.csv")
        df_e = get_clean_df("CSV_E.csv")

        # [3] ì—¬ëŸ¬ ì¢…ëª©ì˜ ë°ì´í„°ë¥¼ í•œêº¼ë²ˆì— ìˆ˜ì§‘
        all_data_a, all_data_e = [], []
        ticker_col_a = next((c for c in df_a.columns if c.lower() in ['ticker', 'code']), 'ticker')
        ticker_col_e = next((c for c in df_e.columns if c.lower() in ['ticker', 'code']), 'ticker')

        for t in target_tickers:
            row_a = df_a[df_a[ticker_col_a].astype(str).str.contains(t)].to_dict(orient='records')
            row_e = df_e[df_e[ticker_col_e].astype(str).str.contains(t)].to_dict(orient='records')
            if row_a: all_data_a.extend(row_a)
            if row_e: all_data_e.extend(row_e)

        # [4] ì‹¤ì‹œê°„ B(ìˆ˜ê¸‰) ë° C(ë§¤í¬ë¡œ)
        data_c = df_c.head(5).to_dict(orient='records') if not df_c.empty else []
        try:
            today = datetime.datetime.now().strftime("%Y%m%d")
            df_b = stock.get_market_net_purchases_of_equities(today, today, "KOSPI")
            b_summary = df_b.loc[['ì™¸êµ­ì¸', 'ê¸°ê´€í•©ê³„'], ['ìˆœë§¤ìˆ˜ê±°ë˜ëŒ€ê¸ˆ']].to_dict()
        except: b_summary = "ì¡°íšŒ ì§€ì—°"

        # [5] Gemini ìµœì¢… ì¢…í•© ë¶„ì„
        prompt = f"""
        ë‹¹ì‹ ì€ ì •í˜¸ë‹˜ì˜ ìˆ˜ì„ í€€íŠ¸ ë¹„ì„œì…ë‹ˆë‹¤. ë¶„ì„ ëŒ€ìƒ: {target_name}
        
        - ëŒ€ìƒ ì¢…ëª© ì½”ë“œë“¤: {target_tickers}
        - ëª¨ë¸ ì ìˆ˜(A): {json.dumps(all_data_a, ensure_ascii=False)}
        - ë§¤í¬ë¡œ(C): {json.dumps(data_c, ensure_ascii=False)}
        - ê°€ê°ì (E): {json.dumps(all_data_e, ensure_ascii=False)}
        - ìˆ˜ê¸‰(B): {json.dumps(b_summary, ensure_ascii=False)}

        ì§€ì‹œì‚¬í•­:
        1. ì œê³µëœ A, E ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê° ì¢…ëª©ì˜ í˜„ì¬ ìƒíƒœë¥¼ ìš”ì•½í•˜ì„¸ìš”.
        2. {target_name}ì˜ êµ¬ì„±ì´ í˜„ì¬ ì‹œì¥ ë§¤í¬ë¡œ(C) ë° ìˆ˜ê¸‰(B)ê³¼ ì˜ ì–´ìš¸ë¦¬ëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”.
        3. 'ë¯¸ìƒ ì¢…ëª©'ì´ë‚˜ 'ë°ì´í„° ì—†ìŒ'ì´ë¼ëŠ” ë§ì€ í”¼í•˜ê³ , ì œê³µëœ ìˆ˜ì¹˜ë¥¼ ìµœëŒ€í•œ í™œìš©í•´ ì „ëµì„ ì œì‹œí•˜ì„¸ìš”.
        """

        response = client.models.generate_content(model="gemini-2.0-flash", contents=prompt)
        return {"analysis": response.text}

    except Exception as e:
        return {"analysis": f"ğŸš¨ ì‹œìŠ¤í…œ ì—°ê²° ì˜¤ë¥˜: {str(e)}"}
