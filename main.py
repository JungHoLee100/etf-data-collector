import pandas as pd
import os, json, requests, datetime, base64
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from google import genai
import pdfplumber
from pykrx import stock
import yfinance as yf
from io import BytesIO

app = FastAPI()
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
GITHUB_USER = "JungHoLee100"
REPO_NAME = "etf-data-collector"
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

# GitHub íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜
def github_file(path, content=None, method="GET"):
    url = f"https://api.github.com/repos/{GITHUB_USER}/{REPO_NAME}/contents/{path}"
    headers = {"Authorization": f"token {GITHUB_TOKEN}", "Accept": "application/vnd.github.v3+json"}
    if method == "GET":
        res = requests.get(url, headers=headers)
        if res.status_code == 200:
            info = res.json()
            return json.loads(base64.b64decode(info['content']).decode('utf-8-sig')), info['sha']
        return None, None
    else:
        _, sha = github_file(path)
        payload = {"message": "Update Portfolio", "content": base64.b64encode(content.encode('utf-8')).decode('utf-8')}
        if sha: payload["sha"] = sha
        return requests.put(url, headers=headers, json=payload)

@app.get("/api/init")
async def init():
    base_url = f"https://raw.githubusercontent.com/{GITHUB_USER}/{REPO_NAME}/main"
    data = {}
    for k, v in {"A": "CSV_A_Analysis.csv", "C": "CSV_C.csv", "E": "CSV_E.csv"}.items():
        try: data[k] = pd.read_csv(f"{base_url}/{v}", encoding='utf-8-sig').fillna(0).to_dict(orient="records")
        except: data[k] = []
    port, _ = github_file("portfolio.json")
    return {"static": data, "portfolio": port or {"holdings": []}}

@app.post("/api/portfolio/save")
async def save_port(req: Request):
    data = await req.json()
    github_file("portfolio.json", content=json.dumps(data, ensure_ascii=False), method="PUT")
    return {"status": "success"}

@app.post("/api/deep-analyze")
async def deep_analyze(req: Request):
    info = await req.json()
    code, name = str(info.get("code")), info.get("name")
    
    # --- [1] CSV A, C, E ë°ì´í„° ë¡œë“œ (Gemini ì£¼ì…ìš©) ---
    base_url = f"https://raw.githubusercontent.com/{GITHUB_USER}/{REPO_NAME}/main"
    try:
        df_a = pd.read_csv(f"{base_url}/CSV_A_Analysis.csv", encoding='utf-8-sig')
        df_c = pd.read_csv(f"{base_url}/CSV_C.csv", encoding='utf-8-sig') # ğŸ‘ˆ ëˆ„ë½ëœ C ì¶”ê°€
        df_e = pd.read_csv(f"{base_url}/CSV_E.csv", encoding='utf-8-sig')
        
        target_a = df_a[df_a['ticker'] == code].to_dict(orient='records')
        macro_c = df_c.head(10).to_dict(orient='records') # ğŸ‘ˆ ì‹œì¥ ì „ì²´ ë§¤í¬ë¡œ ì •ë³´
        target_e = df_e[df_e['ticker'] == code].to_dict(orient='records')
    except:
        target_a, macro_c, target_e = [], [], []

    # --- [2] PDF ë¶„ì„ (ê°œë³„ ì¢…ëª©ëª… ì¶”ì¶œ) ---
    pdf_stocks = "PDF ì •ë³´ ì—†ìŒ"
    try:
        res = requests.get(f"https://api.github.com/repos/{GITHUB_USER}/{REPO_NAME}/contents/reports", 
                           headers={"Authorization": f"token {GITHUB_TOKEN}"})
        files = res.json()
        target_pdf = next((f for f in files if f"({code})" in f['name']), None)
        if target_pdf:
            pdf_res = requests.get(target_pdf['download_url'])
            with pdfplumber.open(BytesIO(pdf_res.content)) as pdf:
                text = "\n".join([p.extract_text() for p in pdf.pages[:3]])
                extract_res = client.models.generate_content(
                    model="gemini-2.0-flash", 
                    contents=f"ì´ ETF ë³´ê³ ì„œ í…ìŠ¤íŠ¸ì—ì„œ ìƒìœ„ 5ê°œ ë³´ìœ  ì¢…ëª©ëª…ë§Œ ë¦¬ìŠ¤íŠ¸ë¡œ ë½‘ì•„ì¤˜: {text}"
                )
                pdf_stocks = extract_res.text
    except: pass

    # --- [3] ì‹¤ì‹œê°„ ìˆ˜ê¸‰(B) ë° ETF ìƒíƒœ(D) ---
    today = datetime.datetime.now().strftime("%Y%m%d")
    try:
        df_b = stock.get_market_net_purchases_of_equities(today, today, "KOSPI")
        b_data = df_b.loc[['ì™¸êµ­ì¸', 'ê¸°ê´€í•©ê³„'], ['ìˆœë§¤ìˆ˜ê±°ë˜ëŒ€ê¸ˆ']].to_dict()
        ticker_yf = yf.Ticker(f"{code}.KS" if not code.startswith('k') else f"{code}.KQ")
        hist = ticker_yf.history(period="30d")
        d_data = f"í˜„ì¬ê°€: {hist['Close'].iloc[-1]}, 20ì¼í‰ê· : {hist['Close'].rolling(20).mean().iloc[-1]:.2f}"
    except: b_data, d_data = "ì¡°íšŒ ë¶ˆê°€", "ì¡°íšŒ ë¶ˆê°€"

    # --- [4] Gemini ì¢…í•© ì¶”ë¡  (A, C, E, B, D, PDF ìœµí•©) ---
    prompt = f"""
    ë‹¹ì‹ ì€ ì •í˜¸ë‹˜ì˜ ìˆ˜ì„ í€€íŠ¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ {name}({code})ì— ëŒ€í•œ íˆ¬ì ì „ëµì„ ìˆ˜ë¦½í•˜ì„¸ìš”.
    
    1. ëª¨ë¸ ì§€í‘œ(A): {json.dumps(target_a, ensure_ascii=False)}
    2. ì‹œì¥ ë§¤í¬ë¡œ í™˜ê²½(C): {json.dumps(macro_c, ensure_ascii=False)}
    3. ìƒì„¸ ê°€ê°ì (E): {json.dumps(target_e, ensure_ascii=False)}
    4. ì‹¤ì‹œê°„ ì‹œì¥ ìˆ˜ê¸‰(B): {json.dumps(b_data, ensure_ascii=False)}
    5. ETF ê°€ê²© ìƒíƒœ(D): {d_data}
    6. PDF ë¦¬í¬íŠ¸ë‚´ ìƒìœ„ ì¢…ëª©: {pdf_stocks}
    
    [ë¯¸ì…˜]
    - CSV_Cì˜ ë§¤í¬ë¡œ ìƒí™©ì´ í˜„ì¬ ì¢…ëª©ì˜ Aë“±ê¸‰ê³¼ Eìƒì„¸ ì ìˆ˜ì— ì–´ë–¤ ì˜í–¥ì„ ì£¼ëŠ”ì§€ ë¶„ì„í•˜ì„¸ìš”.
    - PDFì—ì„œ ë‚˜ì˜¨ ìƒìœ„ ì¢…ëª©ë“¤ì˜ ê¸°ì„¸ì™€ íŒŒìƒ ìˆ˜ê¸‰(B)ì„ ê³ ë ¤í•´ 'ë§¤ìˆ˜/ë³´ìœ /ë§¤ë„' ê²°ë¡ ì„ ë‚´ë¦¬ì„¸ìš”.
    - CSV_A_Analysis ë¦¬ìŠ¤íŠ¸ ì¤‘ ë“±ê¸‰ì´ ë†’ì€ ìœ ì‚¬ ì¢…ëª© 3ê°œë¥¼ 'ì¢…ëª©ëª…(ì½”ë“œ)' í˜•ì‹ìœ¼ë¡œ ì¶”ì²œí•˜ì„¸ìš”.
    """
    
    response = client.models.generate_content(model="gemini-2.0-flash", contents=prompt)
    return {"analysis": response.text}
